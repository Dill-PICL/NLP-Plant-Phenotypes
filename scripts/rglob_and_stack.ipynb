{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_rowstack_dataframes(basedir, filename, path_keyword=None):\n",
    "\t\"\"\"Combine all files found under this directory or its subdirectories that match this file name and return the stacked dataframe.\n",
    "\t\n",
    "\tArgs:\n",
    "\t\tbasedir (str): The base directory to recursively search under.\n",
    "\t\n",
    "\t\tfilename (str): The final path component to use to look for compatible files.\n",
    "\t\n",
    "\t\tpath_keyword (str): A string that has to be presented in the full path or that file is not used, optional.\n",
    "\t\n",
    "\t\n",
    "\tReturns:\n",
    "\t\tpandas.DataFrame: A dataframe resulting from stacking all files under that directory with the provided name.\n",
    "\t\"\"\"\n",
    "\tdfs = []\n",
    "\tfor path in Path(basedir).rglob(filename):\n",
    "\t\tif (path_keyword == None) or (path_keyword in str(path)):\n",
    "\t\t\tdfs.append(pd.read_csv(path))\n",
    "\tif len(dfs)>1:\n",
    "\t\tdf = pd.concat(dfs)\n",
    "\t\tdf.reset_index(drop=True, inplace=True)\n",
    "\t\treturn(df)\n",
    "\telse:\n",
    "\t\treturn(None)\n",
    "\t\t\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def columnstack_distances_dataframes(basedir, filename, path_keyword=None):\n",
    "\t\"\"\"Combine all files found under this directory or its subdirectories that match this file name and return the stacked dataframe.\n",
    "\t\n",
    "\tArgs:\n",
    "\t\tbasedir (str): The base directory to recursively search under.\n",
    "\t\n",
    "\t\tfilename (str): The final path component to use to look for compatible files.\n",
    "\t\n",
    "\t\tpath_keyword (str): A string that has to be presented in the full path or that file is not used, optional.\n",
    "\t\n",
    "\t\n",
    "\tReturns:\n",
    "\t\tpandas.DataFrame: A dataframe resulting from stacking all files under that directory with the provided name.\n",
    "\t\"\"\"\n",
    "\tdfs = []\n",
    "\tfor path in Path(basedir).rglob(filename):\n",
    "\t\tif (path_keyword == None) or (path_keyword in str(path)):\n",
    "\t\t\tdfs.append(pd.read_csv(path))\n",
    "\tif len(dfs)>1:\n",
    "\t\tshared_columns = [\"group_id\", \"full_name\", \"n\"]\n",
    "\t\tdf_final = reduce(lambda left,right: pd.merge(left,right,on=shared_columns, how=\"inner\"), dfs)\n",
    "\t\tfor df in dfs:\n",
    "\t\t\tassert df_final.shape[0] == df.shape[0]\n",
    "\t\treturn(df_final)\n",
    "\telse:\n",
    "\t\treturn(None)\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the file that maps names used internally to names used in figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "naming_dataframe_path = \"../names.tsv\"\n",
    "name_df = pd.read_csv(naming_dataframe_path, sep=\"\\t\")\n",
    "name_to_display_name = dict(zip(name_df[\"name_in_notebook\"].values, name_df[\"name\"]))\n",
    "name_to_order = dict(zip(name_df[\"name_in_notebook\"].values, name_df[\"order\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should we check paths for a keyword?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sys.argv)>1:\n",
    "\tpath_keyword = sys.argv[1]\n",
    "else:\n",
    "\tpath_keyword = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new output folder to hold the stacked tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if path_keyword == None:\n",
    "\tOUTPUT_DIR = os.path.join(\"../outputs\",\"{}_{}_{}\".format(\"stacked\",datetime.datetime.now().strftime('%m_%d_%Y_h%Hm%Ms%S'),random.randrange(1000,9999)))\n",
    "else:\n",
    "\tOUTPUT_DIR = os.path.join(\"../outputs\",\"{}_{}_{}_{}\".format(\"stacked\",datetime.datetime.now().strftime('%m_%d_%Y_h%Hm%Ms%S'),random.randrange(1000,9999),path_keyword))\n",
    "os.mkdir(OUTPUT_DIR)\n",
    "\t\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where to look for these files to stack?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASEDIR = \"../outputs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The names of the final path components for files that should be stacked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILES_TO_BE_STACKED = [\n",
    "\t\"approaches.csv\",\n",
    "\t\"auc.csv\",\n",
    "\t\"f1_max.csv\",\n",
    "\t\"f2_max.csv\",\n",
    "\t\"full_table_with_all_metrics.csv\",\n",
    "\t\"precision_recall_curves.csv\",\n",
    "\t\"histograms.csv\",\n",
    "\t\"correlations.csv\",\n",
    "\t\"all_pmn_only_within_distances_melted.csv\",\n",
    "\t\"all_kegg_only_within_distances_melted.csv\",\n",
    "\t\"all_subsets_within_distances_melted.csv\",\n",
    "\t\"curated_pmn_only_within_distances_melted.csv\",\n",
    "\t\"curated_kegg_only_within_distances_melted.csv\",\n",
    "\t\"curated_subsets_within_distances_melted.csv\"\n",
    "]\n",
    "\t\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of those files, stack them and write to a new file. Sort them if there is a column named \"order\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in FILES_TO_BE_STACKED:\n",
    "    new_filename = \"stacked_{}\".format(filename)\n",
    "    df = recursive_rowstack_dataframes(BASEDIR, filename, path_keyword)\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        if \"name_key\" in df.columns:\n",
    "            all_old_columns = df.columns\n",
    "            df[\"name_value\"] = df[\"name_key\"].map(name_to_display_name)\n",
    "            df[\"order\"] = df[\"name_key\"].map(name_to_order)\n",
    "            new_columns = [\"name_value\",\"order\"]\n",
    "            new_columns.extend([x for x in all_old_columns if x != \"order\"])\n",
    "            df = df[new_columns]\n",
    "        if \"order\" in df.columns:\n",
    "            df.sort_values(by=[\"order\"], inplace=True)\n",
    "        df.to_csv(os.path.join(OUTPUT_DIR,new_filename), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished vertically stacking output files\n"
     ]
    }
   ],
   "source": [
    "print(\"finished vertically stacking output files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ones that are stacked horizontally and require re-organization that's different than the above files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILES_TO_BE_STACKED = [\n",
    "\t\"all_pmn_only_within_distances.csv\",\n",
    "\t\"all_kegg_only_within_distances.csv\",\n",
    "\t\"all_subsets_within_distances.csv\",\n",
    "\t\"curated_pmn_only_within_distances.csv\",\n",
    "\t\"curated_kegg_only_within_distances.csv\",\n",
    "\t\"curated_subsets_within_distances.csv\",\n",
    "]\n",
    "\t\n",
    "for filename in FILES_TO_BE_STACKED:\n",
    "\tnew_filename = \"stacked_{}\".format(filename)\n",
    "\tdf = columnstack_distances_dataframes(BASEDIR, filename, path_keyword)\n",
    "\tif isinstance(df, pd.DataFrame):\n",
    "\t\tif \"order\" in df.columns:\n",
    "\t\t\tdf.sort_values(by=[\"order\"], inplace=True)\n",
    "\t\tdf.to_csv(os.path.join(OUTPUT_DIR,new_filename), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished horizontally stacking output files\n"
     ]
    }
   ],
   "source": [
    "print(\"finished horizontally stacking output files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "corn",
   "language": "python",
   "name": "corn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
